# websocket_tutorial

Example code for a locally run AI server written in python. Expects an LLM being run through llama.cpp https://github.com/ggml-org/llama.cpp

Video tutorial: https://youtu.be/cKo3TbkgcXs
