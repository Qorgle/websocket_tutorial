# websocket_tutorial

Example code for a locally run AI server written in python. Expects an LLM being run through llama.cpp https://github.com/ggml-org/llama.cpp
